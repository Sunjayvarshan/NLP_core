{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog does_this_has_a_vector :  True is_this_word_out_of_vocabulary :  False\n",
      "cat does_this_has_a_vector :  True is_this_word_out_of_vocabulary :  False\n",
      "cake does_this_has_a_vector :  True is_this_word_out_of_vocabulary :  False\n",
      "chess does_this_has_a_vector :  True is_this_word_out_of_vocabulary :  False\n",
      "sekiro does_this_has_a_vector :  False is_this_word_out_of_vocabulary :  True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('dog cat cake chess sekiro')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \"does_this_has_a_vector : \",token.has_vector, \"is_this_word_out_of_vocabulary : \" ,token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.0176e-01,  3.7057e-01,  2.1281e-02, -3.4125e-01,  4.9538e-02,\n",
       "        2.9440e-01, -1.7376e-01, -2.7982e-01,  6.7622e-02,  2.1693e+00,\n",
       "       -6.2691e-01,  2.9106e-01, -6.7270e-01,  2.3319e-01, -3.4264e-01,\n",
       "        1.8311e-01,  5.0226e-01,  1.0689e+00,  1.4698e-01, -4.5230e-01,\n",
       "       -4.1827e-01, -1.5967e-01,  2.6748e-01, -4.8867e-01,  3.6462e-01,\n",
       "       -4.3403e-02, -2.4474e-01, -4.1752e-01,  8.9088e-02, -2.5552e-01,\n",
       "       -5.5695e-01,  1.2243e-01, -8.3526e-02,  5.5095e-01,  3.6410e-01,\n",
       "        1.5361e-01,  5.5738e-01, -9.0702e-01, -4.9098e-02,  3.8580e-01,\n",
       "        3.8000e-01,  1.4425e-01, -2.7221e-01, -3.7016e-01, -1.2904e-01,\n",
       "       -1.5085e-01, -3.8076e-01,  4.9583e-02,  1.2755e-01, -8.2788e-02,\n",
       "        1.4339e-01,  3.2537e-01,  2.7226e-01,  4.3632e-01, -3.1769e-01,\n",
       "        7.9405e-01,  2.6529e-01,  1.0135e-01, -3.3279e-01,  4.3117e-01,\n",
       "        1.6687e-01,  1.0729e-01,  8.9418e-02,  2.8635e-01,  4.0117e-01,\n",
       "       -3.9222e-01,  4.5217e-01,  1.3521e-01, -2.8878e-01, -2.2819e-02,\n",
       "       -3.4975e-01, -2.2996e-01,  2.0224e-01, -2.1177e-01,  2.7184e-01,\n",
       "        9.1703e-02, -2.0610e-01, -6.5758e-01,  1.8949e-01, -2.6756e-01,\n",
       "        9.2639e-02,  4.3316e-01, -4.8868e-01, -3.8309e-01, -2.1910e-01,\n",
       "       -4.4183e-01,  9.8044e-01,  6.7423e-01,  8.4003e-01, -1.8169e-01,\n",
       "        1.7385e-01,  4.1848e-01,  1.6098e-01, -1.0490e-01, -4.1965e-01,\n",
       "       -3.5660e-01, -1.6837e-01, -6.3458e-01,  3.8422e-01, -3.5043e-01,\n",
       "        1.7486e-01,  5.3528e-01,  2.0143e-01,  3.7877e-02,  4.7105e-01,\n",
       "       -4.4344e-01,  1.6840e-01, -1.6685e-01, -2.4022e-01, -1.0077e-01,\n",
       "        3.0334e-01,  4.2730e-01,  3.3803e-01, -4.3481e-01,  1.1343e-01,\n",
       "        6.1958e-02,  6.1808e-02, -1.4007e-01,  8.2018e-02, -3.9130e-02,\n",
       "        5.1442e-02,  2.8725e-01,  5.8025e-01, -5.7641e-01, -3.4652e-01,\n",
       "        1.0132e-01,  1.4463e-01,  1.1569e-02, -3.3701e-01, -1.7586e-01,\n",
       "       -3.5724e-01, -2.1423e-01,  1.1429e-02,  4.7645e-01, -3.7463e-02,\n",
       "       -2.9488e-01, -1.7465e-01,  3.0255e-01,  6.0317e-01, -6.6790e-02,\n",
       "       -2.7050e+00, -7.0308e-01,  4.0548e-01,  6.2874e-01,  6.3080e-01,\n",
       "       -5.4513e-01, -9.6191e-03,  2.6533e-01,  2.3391e-01, -5.1886e-02,\n",
       "       -6.5759e-03,  1.8573e-02, -4.5693e-01, -7.0351e-02, -3.0621e-01,\n",
       "       -1.4018e-02, -2.0408e-01,  3.7100e-01, -3.2354e-01, -8.4646e-01,\n",
       "        2.7092e-01, -1.1961e-01, -9.5576e-02, -6.0464e-01,  4.2409e-02,\n",
       "        2.4656e-01,  3.8445e-02, -2.5467e-02, -9.2908e-02, -2.1356e-01,\n",
       "        3.6120e-01,  1.9113e-02,  6.2741e-02, -1.3083e-01, -1.5146e-03,\n",
       "        5.8238e-01, -1.8956e-01,  7.8105e-01,  1.0477e-02,  1.0928e+00,\n",
       "        1.0140e-01, -3.6248e-01, -1.1962e-01, -3.4462e-01, -5.5704e-01,\n",
       "        2.5797e-01,  3.3356e-01,  3.3194e-01, -3.1298e-01, -7.5547e-01,\n",
       "       -7.5290e-01, -9.3072e-02, -1.1173e-01, -5.7251e-01,  1.6639e-01,\n",
       "        6.3579e-01,  2.4006e-01, -2.9211e-01,  9.0182e-01,  1.2425e-01,\n",
       "       -5.7751e-01,  4.7986e-02, -4.2748e-01,  2.4446e-01,  4.7232e-02,\n",
       "        3.5694e-01,  4.4241e-01, -2.3055e-01,  6.6037e-01, -7.3983e-03,\n",
       "       -3.7857e-01,  2.2759e-01, -3.7138e-01,  3.1055e-01, -7.2105e-02,\n",
       "       -2.4490e-01, -3.9761e-02,  5.3650e-01, -4.1478e-01,  1.6563e-01,\n",
       "        3.3707e-01,  1.0920e-01,  3.7219e-01, -5.5727e-01, -7.8060e-01,\n",
       "        1.4251e-01, -3.5828e-01,  4.1638e-01,  2.1446e-01,  1.8410e-01,\n",
       "       -4.7704e-01, -2.2005e-02, -2.3634e-01, -2.2840e-01,  3.4722e-01,\n",
       "        2.3667e-01,  7.4249e-02, -8.8416e-02,  2.8618e-01, -4.6942e-01,\n",
       "       -4.3914e-01, -2.6474e-01, -3.0690e-01, -1.5260e-01, -8.4870e-02,\n",
       "        2.8410e-01, -1.8481e-01, -2.2122e-01, -1.1169e-01, -2.5241e-02,\n",
       "        4.5968e-02,  3.5343e-02,  2.2467e-01,  5.1556e-01, -6.5137e-04,\n",
       "        9.9559e-02, -1.4215e-01,  2.0136e-01,  2.8334e-01, -2.8772e-01,\n",
       "        3.7766e-02, -3.7608e-01, -1.1681e-01, -6.7020e-01, -4.6265e-02,\n",
       "        3.8784e-01, -3.2295e-02, -5.4291e-02, -4.5384e-01,  1.9552e-01,\n",
       "       -2.9470e-01,  8.5009e-01,  1.0345e-01,  9.7010e-02,  1.1339e-01,\n",
       "        3.9502e-01,  5.9043e-02,  2.1978e-01,  1.8845e-01, -1.5891e-01,\n",
       "       -1.0301e-01,  3.3164e-01,  6.1477e-02, -2.9848e-01,  4.4510e-01,\n",
       "        4.7329e-01,  2.6312e-01, -1.8495e-01,  1.4652e-01, -3.1510e-02,\n",
       "        2.2908e-02, -2.5929e-01, -3.0862e-01,  1.7545e-03, -1.8962e-01,\n",
       "        5.4789e-01,  3.1194e-01,  2.4693e-01,  2.9929e-01, -7.4861e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocks <---> stocks:  0.9999999403953552\n",
      "profit <---> stocks:  0.5215064883232117\n",
      "loss <---> stocks:  0.24371524155139923\n",
      "tower <---> stocks:  0.1250014752149582\n",
      "sword <---> stocks:  0.1006237268447876\n",
      "king <---> stocks:  0.11488589644432068\n",
      "company <---> stocks:  0.35963788628578186\n"
     ]
    }
   ],
   "source": [
    "base_token = nlp('stocks')\n",
    "new_token = nlp('stocks profit loss tower sword king company')\n",
    "\n",
    "for token in new_token:\n",
    "    print(f'{token.text} <---> {base_token.text}: ',token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similarity(base_word, words_to_compare):\n",
    "    base_word = nlp(base_word)\n",
    "    doc = nlp(words_to_compare)\n",
    "    for token in doc : \n",
    "        print(f'{token.text} <---> {base_word.text}: ',token.similarity(base_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple <---> iphone:  0.6339781284332275\n",
      "samsung <---> iphone:  0.6678677201271057\n",
      "tesla <---> iphone:  0.15624849498271942\n",
      "dog <---> iphone:  0.1743103712797165\n",
      "china <---> iphone:  0.3995213806629181\n",
      "zucchini <---> iphone:  0.0076086996123194695\n"
     ]
    }
   ],
   "source": [
    "print_similarity('iphone','apple samsung tesla dog china zucchini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the similarity is based purely on training data, so it may be some articles or wikipedia. Thats why the samsung and iphone vectors are similar because they might've been used in the same article or context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp.vocab[\"king\"].vector\n",
    "man = nlp.vocab[\"man\"].vector\n",
    "woman = nlp.vocab[\"woman\"].vector\n",
    "queen = nlp.vocab[\"queen\"].vector\n",
    "\n",
    "result = king - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78808445]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([result], [queen])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
